---
title: "Analyse exploratoire du jeu de données TP5_a25_reg_app"
author: Engel CALON, Bastien CUVILLIER, Camille MILON
output: html_notebook
---

```{css, echo=FALSE}
/* --- Style global --- */
body {
  font-family: "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
  color: #1f1f1f;
  background-color: #f7f8fa;
  line-height: 1.6;
  margin: 0;
  padding: 0;
}

/* --- Conteneur principal --- */
.main-container {
  max-width: 900px;
  margin: 40px auto;
  background-color: white;
  box-shadow: 0 0 15px rgba(0,0,0,0.1);
  border-radius: 10px;
  padding: 40px 60px;
}

/* --- Titre principal --- */
h1.title {
  font-style: italic;
  text-align: center;
  background-color: #022F54; /*#022745;*/
  color: white;
  font-size: 2.2em;
  padding: 25px 15px;
  border-radius: 10px;
  box-shadow: 0 2px 6px rgba(0,0,0,0.15);
  margin-bottom: 10px;
  margin-top: 0;
  font-family: 'Oxygen', sans-serif;
}

/* --- Auteur centré --- */
.author {
  text-align: center;
  font-style: italic;
  color: #333;
  margin-top: 5px;
  margin-bottom: 40px;
  background-color: white;
}

/* --- Titres de sections --- */
h3, h4, h5 {
  color: #0d1b2a;
  font-weight: 600;
  padding: 10px 20px;
  border-radius: 8px;
  margin-top: 40px;
}

h3 {
  background-color: #b3cde0; /* bleu pastel */
}

h4 {
  background-color: #d6e9f7; /* bleu clair */
}

h5 {
  background-color: #e9f3fb;
}

/* --- Code et sorties --- */
pre, code {
  background-color: #1b263b;
  color: #f1f1f1;
  font-family: "Fira Code", monospace;
  border-radius: 6px;
}

pre {
  padding: 12px;
  overflow-x: auto;
}

.r {
  background-color: #0d1b2a;
  color: #f8f9fa;
}

/* --- Texte --- */
p {
  color: #2b2b2b;
  margin: 10px 0 20px;
}

/* --- Liens --- */
a {
  color: #0077b6;
  text-decoration: none;
}
a:hover {
  text-decoration: underline;
}

/* --- Citations --- */
blockquote {
  border-left: 5px solid #a9cce3;
  background-color: #f1f8fb;
  padding: 10px 20px;
  color: #333;
  font-style: italic;
  border-radius: 5px;
}
```

------------------------------------------------------------------------

### TP5_a25_reg_app

Jeu de données dédié à la régression

#### Chargement des données

```{r}
if(!require(here)) install.packages("here")
library(here)
library(magrittr)
library(tidyverse)
# Chemin vers les données

data_path <- here("src", "data", "TP5_a25_reg_app.txt")

# Lecture des données
reg_data <- read.table(
  data_path,
  header = TRUE,
  sep = " ",
  quote = "\"",
  stringsAsFactors = FALSE
)

# y as factor ?

# Aperçu
head(reg_data)
```

```{r}
dim(reg_data)
str(reg_data)
```

Le jeu de données est composé de **500 observations**, de **100 variables numériques** (X1 à X100) et d'une **variable cible numérique** y.

#### Résumé statistique

```{r}
# Résumé statistique simple
summary(reg_data)
```

##### Variables descriptives

-   Les X semblent **toutes bornées entre environ 0 et 10**, probablement issues d’une génération aléatoire uniforme ou d’une normalisation.

-   Les moyennes et médianes des X sont très proches (autour de 5) =\> **symétrie globale** des distributions, pas de fort déséquilibre entre les variables

-   Les plages suggèrent que toutes les variables ont la **même échelle** =\> pas besoin de normalisation (ce qui est étrange pour de la regression...)

-   Les écarts entre les quartiles sont constants =\> **dispersion moyenne constante** entre les variables

##### Variable cible

-   La variable cible y est continue et non bornée, avec une **plage de [-169, 182]** =\> y varie fortement

-   La moyenne et la médiane sont proches =\> **pas d'asymétrie**

-   Valeurs aberrantes possibles (à vérifier par la suite)

```{r}
# Statistiques détaillées
library(psych)
psych::describe(reg_data)
```

```{r}
# Vérification des valeurs manquantes
colSums(is.na(reg_data))
```

Aucune valeur manquante.

#### Valeurs aberrantes

```{r}
library(ggplot2)

vars_cont <- colnames(reg_data)[1:100]

reg_data_long <- reg_data %>% select(all_of(vars_cont)) %>% pivot_longer(cols = everything(), names_to = "variable", values_to = "valeur")

ggplot(reg_data_long, aes(x = variable, y = valeur)) +
  geom_boxplot(outlier.color = "red", fill = "steelblue", alpha = 0.6) +
  theme_minimal() +
  labs(title = "Boxplots des variables X1 à X100")
```

Pas de valeurs aberrantes. Distributions extrêmement uniformes et quasi-identiques entre les variables.

```{r}
ggplot(reg_data, aes(y = y)) +
  geom_boxplot(fill = "orange", color = "black", outlier.color = "red", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Détection des valeurs extrêmes de y")
```

```{r}
# Calcul des seuils
Q1 <- quantile(reg_data$y, 0.25)
Q3 <- quantile(reg_data$y, 0.75)
IQR <- Q3 - Q1

seuil_inf <- Q1 - 1.5 * IQR
seuil_sup <- Q3 + 1.5 * IQR

# Identifier les valeurs aberrantes
outliers_y <- reg_data$y[reg_data$y < seuil_inf | reg_data$y > seuil_sup]
n_outliers <- length(outliers_y)
cat("Nombre de valeurs aberrantes de y :", n_outliers, "\n")

# Afficher les valeurs et leurs indices
which_outliers <- which(reg_data$y < seuil_inf | reg_data$y > seuil_sup)
data.frame(Index = which_outliers, y = reg_data$y[which_outliers])
```

On n'observe qu'une seule valeur abérrante pour y à l'indice 57.

#### Distributions

```{r}
library(tidyverse)
# Histogrammes 
num_vars <- names(reg_data)[sapply(data, is.numeric)]

for (var in num_vars) {
  print(
    ggplot(reg_data, aes_string(x = var)) +
      geom_histogram(bins = 30, fill = "steelblue", color = "white") +
      labs(title = paste("Distribution de", var), x = var, y = "Fréquence") +
      theme_minimal()
  )
}
```

```{r}
# Histogramme et densité
ggplot(reg_data, aes(x = y)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  geom_density(color = "red", size = 1) +
  theme_minimal() +
  labs(title = "Distribution de la variable cible y")
```

Les **variables X1 à X100** semblent suivre des **distributions aléatoires** : distributions relativement uniformes, sans concentration vraiment marquée autour d'une valeur (sauf peut-être pour X57 ?), aucune asymétrie marquée, etc

**y** semble suivre une **loi normale**.

#### Corrélations

```{r}
library(corrplot)
# Matrice de corrélation
cor_mat <- cor(reg_data)
corrplot(cor_mat, method = "color", type = "upper", tl.cex = 0.7,
         title = "Matrice de corrélation entre variables")

# Corrélation de chaque variable avec y
cor_y <- cor(reg_data %>% select(-y), reg_data$y)
cor_y <- sort(cor_y, decreasing = TRUE)
print(cor_y)

# Identifier les variables les plus explicatives (corrélation forte avec y)
top_vars <- names(cor_y)[1:6]
cat("Variables les plus corrélées positivement avec y :\n")
print(top_vars)
```

Les variables ne sont **pas corrélées** entre elles =\> aucune colinéarité, aucune redondance importante =\> aucun intérêt à utiliser Ridge

Par ailleurs, la plupart des variables explicatives ont peu ou pas de relation linéaire forte avec la variable cible y =\> **aucune relation linéaire marquée entre une seule variable et y**

#### Selection de variables
Création d'un jeu d'entrainement pour la sélection de variables
```{r}
set.seed(42)
train_size <- floor(0.7 * nrow(reg_data))
train_indices <- sample(seq_len(nrow(reg_data)), size = train_size)
reg_data_train <- reg_data[train_indices, ]
reg_data_test  <- reg_data[-train_indices, ]
```
##### Méthode forward
```{r}
library('leaps')
reg.forward <- regsubsets(y ~ . , data = reg_data, method = 'forward')
plot(reg.forward, scale = "r2", main = "Sélection — forward (R2)")
```
y ~ X6 + X8 + X42 + X45 + X79 + X84 + X86 + X91

##### Méthode backward
```{r}
library('leaps')
reg.backward <- regsubsets(y ~ . , data = reg_data, method = 'backward')
plot(reg.backward, scale = "r2", main = "Sélection — backward (R2)")
```
y ~ X6 + X8 + X42 + X45 + X79 + X84 + X86 + X91

##### AIC
```{r}
library(MASS)
fit <- glm(y ~ .,data=reg_data, family = "gaussian")
sel.aic <- stepAIC(fit,scope=y ~ .,direction="both")
aic.formula <- formula(sel.aic)
print(formula(sel.aic))
```
y ~ X2 + X3 + X6 + X7 + X8 + X11 + X12 + X14 + X16 + X17 + X18 +
    X19 + X20 + X21 + X22 + X23 + X25 + X27 + X29 + X31 + X33 +
    X34 + X35 + X36 + X37 + X40 + X41 + X42 + X43 + X44 + X45 +
    X46 + X49 + X50 + X52 + X56 + X57 + X58 + X60 + X62 + X64 +
    X68 + X71 + X72 + X73 + X74 + X75 + X77 + X78 + X79 + X80 +
    X81 + X82 + X84 + X85 + X86 + X90 + X91 + X93 + X94 + X96 +
    X97 + X98 + X99 + X100
```{r}
library(MASS)
fit <- glm(y ~ .,data=reg_data, family = "gaussian")
sel.bic <- stepAIC(fit,scope=y ~ .,direction="both",
k=log(nrow(reg_data)))
bic.formula <- formula(sel.bic)
print(formula(sel.bic))
```
y ~ X2 + X3 + X6 + X7 + X8 + X11 + X12 + X16 + X17 + X18 + X19 +
    X20 + X21 + X22 + X25 + X33 + X34 + X35 + X36 + X37 + X40 +
    X41 + X42 + X43 + X44 + X45 + X46 + X49 + X50 + X52 + X56 +
    X57 + X58 + X62 + X71 + X72 + X73 + X74 + X75 + X79 + X80 +
    X81 + X84 + X85 + X86 + X90 + X91 + X93 + X94 + X96 + X98

##### Valider les sélections 
```{r}
library(MASS)
model.reg <- glm(y ~ ., data=reg_data_train, family="gaussian")
model.reg.aic <- glm(aic.formula, data=reg_data_train, family="gaussian")
model.reg.bic <- glm(bic.formula, data=reg_data_train, family="gaussian")
model.reg.forward <- glm(y ~ X6 + X8 + X42 + X45 + X79 + X84 + X86 + X91, data=reg_data_train, family="gaussian")
model.reg.backward <- glm(y ~ X6 + X8 + X42 + X45 + X79 + X84 + X86 + X91, data=reg_data_train, family="gaussian")

pred.reg <- predict(model.reg, newdata=reg_data_test, type="response")
pred.reg.aic <- predict(model.reg.aic, newdata=reg_data_test, type="response")
pred.reg.bic <- predict(model.reg.bic, newdata=reg_data_test, type="response")
pred.reg.forward <- predict(model.reg.forward, newdata=reg_data_test, type="response")
pred.reg.backward <- predict(model.reg.backward, newdata=reg_data_test, type="response")

# Calcul du MSE
mse.reg <- mean((reg_data_test$y - pred.reg)^2)
mse.reg.aic <- mean((reg_data_test$y - pred.reg.aic)^2)
mse.reg.bic <- mean((reg_data_test$y - pred.reg.bic)^2)
mse.reg.forward <- mean((reg_data_test$y - pred.reg.forward)^2) 
mse.reg.backward <- mean((reg_data_test$y - pred.reg.backward)^2)

cat("\nRESULTATS SELECTION DE VARIABLES\n")
cat("MSE Full     : ", mse.reg, ", formule ", "complete", "\n")
cat("MSE AIC :  ", mse.reg.aic, ", formule ", as.character(aic.formula)[3], "\n")
cat("MSE BIC      : ", mse.reg.bic, ", formule ", as.character(bic.formula)[3] , "\n")
cat("MSE Forward  : ", mse.reg.forward,", formule ", "y ~ X6 + X8 + X42 + X45 + X79 + X84 + X86 + X91" , "\n")
cat("MSE Backward : ", mse.reg.backward,", formule ", "y ~ X6 + X8 + X42 + X45 + X79 + X84 + X86 + X91" , "\n")

plot(reg_data_test$y)
plot(pred.reg.bic)

```

#### Tests de régresseurs

Au vu des données, les deux meilleurs classifieurs devraient être la régression linéaire et LASSO.

##### Régression linéaire

```{r}
library(dplyr)

set.seed(123)

# Préparation des données
X <- reg_data %>% select(-y)
y <- reg_data$y
n <- nrow(reg_data)

# Validation croisée 10-fold
k <- 10
folds <- sample(rep(1:k, length.out = n))

rmse_fold <- function(y_true, y_pred) {
  sqrt(mean((y_true - y_pred)^2))
}

rmse_results <- numeric(k)

for (i in 1:k) {
  test_idx <- which(folds == i)
  train_idx <- setdiff(1:n, test_idx)
  
  train_df <- reg_data[train_idx, ]
  test_df <- reg_data[test_idx, ]
  
  # Régression linéaire
  lm_mod <- lm(y ~ ., data = train_df)
  
  # Prédiction
  pred <- predict(lm_mod, newdata = test_df)
  
  # RMSE
  rmse_results[i] <- rmse_fold(test_df$y, pred)
}

# Résultat
mean_rmse <- mean(rmse_results)
sd_rmse <- sd(rmse_results)

cat("RMSE moyen :", mean_rmse, "\n")
cat("Écart-type du RMSE :", sd_rmse, "\n")
```

##### LASSO

Le jeu de données contient bcp de variables, surtout par rapport au nombre d'observations. Il peut donc être intéressant d'utiliser LASSO pour faire de la sélection de variables. (Aucun intérêt ici à utiliser Ridge ou elastic net)

```{r}
# Préparation
library(glmnet)
```

```{r}
X <- as.matrix(reg_data %>% select(-y))
y <- reg_data$y

# Traitement de l’outlier
y_no_outlier <- y[y > quantile(y, 0.01)]  

# Validation croisée LASSO
set.seed(123)
cv_lasso <- cv.glmnet(X, y, alpha = 1, standardize = TRUE)
plot(cv_lasso)

# Coefficients retenus
coff <- coef(cv_lasso, s = "lambda.min")

# Évaluation
pred <- predict(cv_lasso, newx = X, s = "lambda.min")
R2 <- cor(pred, y)^2
cat("R² =", R2)
```

LASSO utilise globalement toutes les variables (sauf X1, X4, X28, X54, X63, X65, X66, X69, X86).\
R² = 0.9737215

##### Comparaison de tous les modèles de régression

```{r}
library(glmnet)
library(randomForest)
library(xgboost)
library(dplyr)
library(splines)
library(mgcv)
library(autogam)
library(rpart)

set.seed(123)

# Préparation des données
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y

# Standardisation pour modèles linéaires régularisés
X_scaled <- scale(X)


# Validation croisée 10-fold
k <- 5
folds <- sample(rep(1:k, length.out = nrow(X_scaled)))

rmse_fold <- function(y_true, y_pred) {
  sqrt(mean((y_true - y_pred)^2))
}
mse_fold <- function(y_true, y_pred) {
  mean((y_true - y_pred)^2)
}

# Stockage des RMSE
results <- list(LM = numeric(k),
                Ridge = numeric(k),
                Lasso = numeric(k),
                RF = numeric(k),
                XGB = numeric(k),
                SPLGAM = numeric(k),
                REGTREE = numeric(k),
                PRUNED_REGTREE = numeric(k))

for (i in 1:k) {
  test_idx <- which(folds == i)
  train_idx <- setdiff(1:nrow(X_scaled), test_idx)
  
  X_train <- X_scaled[train_idx, , drop = FALSE]
  y_train <- y[train_idx]
  X_test <- X_scaled[test_idx, , drop = FALSE]
  y_test <- y[test_idx]
  
  
  # Régression linéaire
  train_df <- data.frame(y = y_train, X_train)
  colnames(train_df)[-1] <- colnames(reg_data)[-ncol(reg_data)]
  
  test_df <- data.frame(X_test)
  colnames(test_df) <- colnames(train_df)[-1]
  
  lm_mod <- lm(y ~ ., data = train_df)
  pred_lm <- predict(lm_mod, newdata = test_df)
  #results$LM[i] <- rmse_fold(y_test, pred_lm)
  results$LM[i] <- mse_fold(y_test, pred_lm)
  
  # Splines + GAM
  splgam_mod <- autogam(data=train_df,y_col="y")
  pred_splgam <- predict(splgam_mod, test_df, type = "response")
  #results$SPLGAM[i] <- rmse_fold(y_test, pred_splgam)
  results$SPLGAM[i] <- mse_fold(y_test, pred_splgam)
  
  # Ridge
  ridge_mod <- cv.glmnet(X_train, y_train, alpha = 0, nfolds = 5)
  pred_ridge <- predict(ridge_mod, X_test, s = "lambda.min")
  #results$Ridge[i] <- rmse_fold(y_test, pred_ridge)
  results$Ridge[i] <- mse_fold(y_test, pred_ridge)
  
  # Lasso
  lasso_mod <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 5)
  pred_lasso <- predict(lasso_mod, X_test, s = "lambda.min") # Test 1se lambda
  #results$Lasso[i] <- rmse_fold(y_test, pred_lasso)
  results$Lasso[i] <- mse_fold(y_test, pred_lasso)
  
  # Random Forest
  rf_mod <- randomForest(x = X_train, y = y_train, ntree = 200)
  pred_rf <- predict(rf_mod, X_test)
  #results$RF[i] <- rmse_fold(y_test, pred_rf)
  results$RF[i] <- mse_fold(y_test, pred_rf)

  # XGBoost
  xgb_train <- xgb.DMatrix(data = X_train, label = y_train)
  xgb_test <- xgb.DMatrix(data = X_test, label = y_test)
  xgb_mod <- xgboost(data = xgb_train, nrounds = 100, objective = "reg:squarederror", verbose = 0)
  pred_xgb <- predict(xgb_mod, xgb_test)
  # results$XGB[i] <- rmse_fold(y_test, pred_xgb)
  results$XGB[i] <- mse_fold(y_test, pred_xgb)
  
  # Regression Tree + pruned
  tree_mod <- rpart(y ~ ., data=train_df, method="anova",control = rpart.control(minbucket = 10, cp = 0))
  pred_tree <- predict(tree_mod, newdata=test_df)
  # results$REGTREE[i] <- rmse_fold(y_test, pred_tree)
  results$REGTREE[i] <- mse_fold(y_test, pred_tree)
    # pruning tree
  i_min <- which.min(tree_mod$cptable[, 4])
  x <- tree_mod$cptable[i_min, 4] + tree_mod$cptable[i_min, 5]
  ii <- which(tree_mod$cptable[, 4] <= x)
  cp_opt <- tree_mod$cptable[min(ii), 1]
  pruned_tree <- prune(tree_mod, cp=cp_opt)
  pred_tree_pruned <- predict(pruned_tree, newdata=test_df)
  #results$PRUNED_REGTREE[i] <- rmse_fold(y_test, pred_tree_pruned)
  results$PRUNED_REGTREE[i] <- mse_fold(y_test, pred_tree_pruned)
}


# Comparaison
mean_mse <- sapply(results, mean)
sd_mse <- sapply(results, sd)

res_df <- data.frame(Model = names(mean_mse),
                     MSE_Mean = mean_mse,
                     MSE_SD = sd_mse)
print(res_df)

# Meilleur modèle
best_model <- res_df$Model[which.min(res_df$MSE_Mean)]
cat("\nMeilleur modèle selon RMSE moyen :", best_model, "\n")
```

Les résultats confirment bien les attentes =\> le meilleur modèle en termes de RMSE est LASSO

```{r}
library(glmnet)
library(randomForest)
library(xgboost)
library(dplyr)
library(splines)
library(mgcv)
library(autogam)
library(rpart)

set.seed(123)

# Préparation des données
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y

# Standardisation pour modèles linéaires régularisés
X_scaled <- scale(X)

# Validation croisée 5-fold
k <- 10
folds <- sample(rep(1:k, length.out = nrow(X_scaled)))

rmse_fold <- function(y_true, y_pred) {
  sqrt(mean((y_true - y_pred)^2))
}
mse_fold <- function(y_true, y_pred) {
  mean((y_true - y_pred)^2)
}

# Stockage des MSE
results <- list(
  LM = numeric(k),
  Ridge = numeric(k),
  Lasso = numeric(k),
  Lasso_Opt = numeric(k),
  Lasso_Sq = numeric(k),
  Lasso_Sqrt = numeric(k),
  Lasso_Log = numeric(k)
)

for (i in 1:k) {
  test_idx <- which(folds == i)
  train_idx <- setdiff(1:nrow(X_scaled), test_idx)
  
  X_train <- X_scaled[train_idx, , drop = FALSE]
  y_train <- y[train_idx]
  X_test <- X_scaled[test_idx, , drop = FALSE]
  y_test <- y[test_idx]
  
  # Transformation des variables pour LASSO
  X_train_sq <- X_train^2
  X_test_sq <- X_test^2
  
  X_train_sqrt <- sqrt(pmax(X_train, 0))
  X_test_sqrt <- sqrt(pmax(X_test, 0))
  
  X_train_log <- log(pmax(X_train, 1e-6))
  X_test_log <- log(pmax(X_test, 1e-6))
  
  # Préparation des data.frames pour LM, GAM, arbre
  train_df <- data.frame(y = y_train, X_train)
  colnames(train_df)[-1] <- colnames(reg_data)[-ncol(reg_data)]
  
  test_df <- data.frame(X_test)
  colnames(test_df) <- colnames(train_df)[-1]
  
  # Régression linéaire
  lm_mod <- lm(y ~ ., data = train_df)
  pred_lm <- predict(lm_mod, newdata = test_df)
  results$LM[i] <- mse_fold(y_test, pred_lm)
  
  # Ridge
  ridge_mod <- cv.glmnet(X_train, y_train, alpha = 0, nfolds = 5)
  pred_ridge <- predict(ridge_mod, X_test, s = "lambda.min")
  results$Ridge[i] <- mse_fold(y_test, pred_ridge)
  
  # Lasso standard
  lasso_mod <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 5)
  pred_lasso <- predict(lasso_mod, X_test, s = "lambda.min")
  results$Lasso[i] <- mse_fold(y_test, pred_lasso)
  
  # Lasso opti
  lasso_cv <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 5)
  pred_lasso_min <- predict(lasso_cv, X_test, s = "lambda.min")
  pred_lasso_1se <- predict(lasso_cv, X_test, s = "lambda.1se")
  
  mse_min <- mse_fold(y_test, pred_lasso_min)
  mse_1se <- mse_fold(y_test, pred_lasso_1se)
  
  if (mse_min <= mse_1se) {
    results$Lasso_Opt[i] <- mse_min
  } else {
    results$Lasso_Opt[i] <- mse_1se
  }
  
  # Lasso carré
  lasso_sq_mod <- cv.glmnet(X_train_sq, y_train, alpha = 1, nfolds = 5)
  pred_lasso_sq <- predict(lasso_sq_mod, X_test_sq, s = "lambda.min")
  results$Lasso_Sq[i] <- mse_fold(y_test, pred_lasso_sq)
  
  # Lasso racine
  lasso_sqrt_mod <- cv.glmnet(X_train_sqrt, y_train, alpha = 1, nfolds = 5)
  pred_lasso_sqrt <- predict(lasso_sqrt_mod, X_test_sqrt, s = "lambda.min")
  results$Lasso_Sqrt[i] <- mse_fold(y_test, pred_lasso_sqrt)
  
  # Lasso log
  lasso_log_mod <- cv.glmnet(X_train_log, y_train, alpha = 1, nfolds = 5)
  pred_lasso_log <- predict(lasso_log_mod, X_test_log, s = "lambda.min")
  results$Lasso_Log[i] <- mse_fold(y_test, pred_lasso_log)
}  
 
# Comparaison
mean_mse <- sapply(results, mean)
sd_mse <- sapply(results, sd)

res_df <- data.frame(Model = names(mean_mse),
                     MSE_Mean = mean_mse,
                     MSE_SD = sd_mse)
print(res_df)

# Meilleur modèle
best_model <- res_df$Model[which.min(res_df$MSE_Mean)]
cat("\nMeilleur modèle selon MSE moyen :", best_model, "\n")
```

utiliser lasso avec x et x^2 pour identifier les carrés d'intérêt puis mélange => Camille
regarder tous les splines appris 1 à 1 => Bastien

##### Test transformations
```{r}
library(glmnet)
library(dplyr)

set.seed(123)

# Données
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y
X_scaled <- scale(X)

varnames <- colnames(X_scaled)

# Transformations
X_sq    <- X_scaled^2
X_sqrt  <- sqrt(pmax(X_scaled, 0))
X_log   <- log(pmax(X_scaled, 1e-6))

test_var <- function(x_base, x_sq, x_sqrt, x_log, y) {
  
  safe_cv <- function(vec, y) {
    
    # Reforce matrice
    Xmat <- matrix(vec, ncol = 1)
    
    # Variance nulle marche pas avec glmnet
    if (sd(Xmat) == 0) return(Inf)
    
    # ajouter une colonne factice => permet de débugger à améliorer plus tard
    Xmat2 <- cbind(Xmat, 0)   
    
    # LASSO
    cv <- cv.glmnet(Xmat2, y, alpha = 1)
    return(min(cv$cvm))
  }
  
  mse_list <- c(
    base = safe_cv(x_base, y),
    sq   = safe_cv(x_sq, y),
    sqrt = safe_cv(x_sqrt, y),
    log  = safe_cv(x_log, y)
  )
  
  names(which.min(mse_list))
}


best_transform <- sapply(
  seq_along(varnames),
  function(j) test_var(
    X_scaled[, j, drop = FALSE][,1],
    X_sq[, j, drop = FALSE][,1],
    X_sqrt[, j, drop = FALSE][,1],
    X_log[, j, drop = FALSE][,1],
    y
  )
)

names(best_transform) <- varnames
best_transform

```

```{r}
df_final <- data.frame(y = y)

for (j in seq_along(varnames)) {
  
  v <- varnames[j]
  
  if (best_transform[v] == "base")
    df_final[[v]] <- X_scaled[, j]
  
  if (best_transform[v] == "sq")
    df_final[[v]] <- X_sq[, j]
  
  if (best_transform[v] == "sqrt")
    df_final[[v]] <- X_sqrt[, j]
  
  if (best_transform[v] == "log")
    df_final[[v]] <- X_log[, j]
}

```

```{r}
formula_final <- as.formula(
  paste("y ~", paste(colnames(df_final)[-1], collapse = " + "))
)

formula_final
```


```{r}
mod_final_lm <- lm(formula_final, data = df_final)
summary(mod_final_lm)
```

```{r}
X_final <- as.matrix(df_final %>% select(-y))

mod_final_lasso <- cv.glmnet(X_final, y, alpha = 1)

mse_final_lasso <- min(mod_final_lasso$cvm)
rmse_final_lasso <- sqrt(mse_final_lasso)

mse_final_lasso
rmse_final_lasso
```

On se rend compte qu'il y a un problème d'échelle donc ci-dessous voici la version avec scale après les transformations :

```{r}
library(glmnet)
library(dplyr)

set.seed(123)

# Données de départ
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y

# Standardisation initiale
X_scaled <- scale(X)
varnames <- colnames(X_scaled)
X_sq    <- X_scaled^2
X_sqrt  <- sqrt(pmax(X_scaled, 0))
X_log   <- log(pmax(X_scaled, 1e-6))

test_var <- function(x_base, x_sq, x_sqrt, x_log, y) {
  
  safe_cv <- function(vec, y) { # à modifier plus tard, function créée pour l'instant pour résoudre le bug => bricolage...
    Xmat <- matrix(vec, ncol = 1)
    if (sd(Xmat) == 0) return(Inf)
    Xmat2 <- cbind(Xmat, 0)
    
    cv <- cv.glmnet(Xmat2, y, alpha = 1)
    min(cv$cvm)
  }
  
  mse_list <- c(
    base = safe_cv(x_base,  y),
    sq   = safe_cv(x_sq,    y),
    sqrt = safe_cv(x_sqrt,  y),
    log  = safe_cv(x_log,   y)
  )
  
  names(which.min(mse_list))
}


best_transform <- sapply(
  seq_along(varnames),
  function(j) test_var(
    X_scaled[, j],
    X_sq[, j],
    X_sqrt[, j],
    X_log[, j],
    y
  )
)

names(best_transform) <- varnames
best_transform

```

```{r}
df_final <- data.frame(y = y)

for (j in seq_along(varnames)) {
  
  v <- varnames[j]
  
  if (best_transform[v] == "base")
    df_final[[v]] <- X_scaled[, j]
  
  if (best_transform[v] == "sq")
    df_final[[v]] <- X_sq[, j]
  
  if (best_transform[v] == "sqrt")
    df_final[[v]] <- X_sqrt[, j]
  
  if (best_transform[v] == "log")
    df_final[[v]] <- X_log[, j]
}
X_final <- scale(df_final %>% select(-y))

mod_final_lasso <- cv.glmnet(X_final, y, alpha = 1)

lambda_opt <- mod_final_lasso$lambda.min
mse_final  <- min(mod_final_lasso$cvm)
rmse_final <- sqrt(mse_final)

lambda_opt
mse_final
rmse_final
```

```{r}
coef_final <- coef(mod_final_lasso, s = "lambda.min")
selected_vars <- rownames(coef_final)[coef_final[,1] != 0]

selected_vars
```

```{r}
vars_kept <- selected_vars[selected_vars != "(Intercept)"]

formula_final <- as.formula(
  paste("y ~", paste(vars_kept, collapse = " + "))
)

mod_refit <- lm(formula_final, data = as.data.frame(cbind(y, X_final)))
summary(mod_refit)

```


##### Test ajout d'interactions
```{r}
library(glmnet)
library(dplyr)

set.seed(123)

# Données de départ
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y

# Standardisation initiale
X_scaled <- scale(X)
varnames <- colnames(X_scaled)

# Génération des polynômes (degré 2) et interactions
# inclut x_i^2 et x_i * x_j pour i < j
X_poly <- X_scaled
for (i in 1:ncol(X_scaled)) {
  X_poly <- cbind(X_poly, X_scaled[,i]^2)
  colnames(X_poly)[ncol(X_poly)] <- paste0(varnames[i], "_sq")
}

for (i in 1:(ncol(X_scaled)-1)) {
  for (j in (i+1):ncol(X_scaled)) {
    X_poly <- cbind(X_poly, X_scaled[,i] * X_scaled[,j])
    colnames(X_poly)[ncol(X_poly)] <- paste0(varnames[i], "_x_", varnames[j])
  }
}

# Standardisation globale
X_poly_scaled <- scale(X_poly)

# Validation croisée k-fold
k <- 10
folds <- sample(rep(1:k, length.out = nrow(X_poly_scaled)))

rmse_fold <- function(y_true, y_pred) sqrt(mean((y_true - y_pred)^2))
mse_fold <- function(y_true, y_pred) mean((y_true - y_pred)^2)

# Stockage des résultats
results <- numeric(k)

for (i in 1:k) {
  test_idx <- which(folds == i)
  train_idx <- setdiff(1:nrow(X_poly_scaled), test_idx)
  
  X_train <- X_poly_scaled[train_idx, , drop = FALSE]
  y_train <- y[train_idx]
  X_test  <- X_poly_scaled[test_idx, , drop = FALSE]
  y_test  <- y[test_idx]
  
  # Elastic Net (alpha = 0.5)
  cv_mod <- cv.glmnet(X_train, y_train, alpha = 0.5, nfolds = 5)
  
  pred <- predict(cv_mod, X_test, s = "lambda.min")
  results[i] <- mse_fold(y_test, pred)
}

# Résultat final
mean_mse <- mean(results)
sd_mse   <- sd(results)
cat("MSE moyen (10-fold) :", mean_mse, "\n")
cat("RMSE moyen (10-fold):", sqrt(mean_mse), "\n")
cat("SD MSE :", sd_mse, "\n")

# Variables sélectionnées par LASSO sur tout le dataset
mod_full <- cv.glmnet(X_poly_scaled, y, alpha = 0.5)
coef_selected <- coef(mod_full, s = "lambda.min")
selected_vars <- rownames(coef_selected)[coef_selected[,1] != 0]
selected_vars

```


##### Comparaison LASSO et Elastic Net
```{r}
library(glmnet)
library(dplyr)

set.seed(123)

# Préparation des données
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y

# Standardisation
X_scaled <- scale(X)

# Validation croisée 10-fold
k <- 10
folds <- sample(rep(1:k, length.out = nrow(X_scaled)))

rmse_fold <- function(y_true, y_pred) sqrt(mean((y_true - y_pred)^2))
mse_fold  <- function(y_true, y_pred) mean((y_true - y_pred)^2)

# Stockage des MSE pour chaque fold
results <- list(
  LASSO      = numeric(k),
  ElasticNet = numeric(k)
)

# Boucle cross-validation
for(i in 1:k){
  
  test_idx  <- which(folds == i)
  train_idx <- setdiff(1:nrow(X_scaled), test_idx)
  
  X_train <- X_scaled[train_idx, , drop = FALSE]
  y_train <- y[train_idx]
  X_test  <- X_scaled[test_idx, , drop = FALSE]
  y_test  <- y[test_idx]
  
  # LASSO pur (alpha = 1)
  lasso_mod <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 5)
  pred_lasso <- predict(lasso_mod, X_test, s = "lambda.min")
  results$LASSO[i] <- mse_fold(y_test, pred_lasso)
  
  # Elastic Net léger (alpha = 0.5)
  en_mod <- cv.glmnet(X_train, y_train, alpha = 0.5, nfolds = 5)
  pred_en <- predict(en_mod, X_test, s = "lambda.min")
  results$ElasticNet[i] <- mse_fold(y_test, pred_en)
}

# Résultats
mean_mse <- sapply(results, mean)
sd_mse   <- sapply(results, sd)

res_df <- data.frame(
  Model = names(mean_mse),
  MSE_Mean = mean_mse,
  MSE_SD   = sd_mse
)
print(res_df)

best_model <- res_df$Model[which.min(res_df$MSE_Mean)]
cat("\nMeilleur modèle selon MSE moyen :", best_model, "\n")

# Refit sur tout le dataset pour LASSO ou Elastic Net choisi
if(best_model == "LASSO"){
  final_mod <- cv.glmnet(X_scaled, y, alpha = 1)
} else {
  final_mod <- cv.glmnet(X_scaled, y, alpha = 0.5)
}

lambda_opt <- final_mod$lambda.min
cat("Lambda optimal :", lambda_opt, "\n")

# Variables sélectionnées
coef_selected <- coef(final_mod, s = "lambda.min")
selected_vars <- rownames(coef_selected)[coef_selected[,1] != 0]
selected_vars

```


##### GLMNET avec optimisation du alpha et du lambda
```{r}
library(glmnet)
library(dplyr)

set.seed(123)

# Préparer les données
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y
X_scaled <- scale(X)

# Grille fine de lambda
lambda_grid <- 10^seq(-2, 2, length.out = 200)

# Explorer alpha proche de LASSO
alpha_grid <- seq(0.8, 1, by = 0.02)

best_mse <- Inf
best_alpha <- NA
best_lambda <- NA
best_model <- NULL

for(a in alpha_grid){
  en_mod <- cv.glmnet(X_scaled, y, alpha = a, nfolds = 10, lambda = lambda_grid)
  mse <- min(en_mod$cvm)
  if(mse < best_mse){
    best_mse <- mse
    best_alpha <- a
    best_lambda <- en_mod$lambda.min
    best_model <- en_mod
  }
}

cat("Meilleur alpha :", best_alpha, "\n")
cat("Lambda correspondant :", best_lambda, "\n")
cat("MSE CV (d'après cv.glmnet) :", best_mse, "\n\n")

# Variables sélectionnées
coef_selected <- coef(best_model, s = "lambda.min")
selected_vars <- rownames(coef_selected)[coef_selected[,1] != 0]
selected_vars <- selected_vars[selected_vars != "(Intercept)"]
cat("Variables sélectionnées :", selected_vars, "\n\n")

# Refit final du modèle sur toutes les données
final_model <- glmnet(X_scaled, y, alpha = best_alpha, lambda = best_lambda)

# Validation croisée manuelle pour MSE réaliste
k <- 10
folds <- sample(rep(1:k, length.out = nrow(X_scaled)))
mse_cv <- numeric(k)

for(i in 1:k){
  test_idx <- which(folds == i)
  train_idx <- setdiff(1:nrow(X_scaled), test_idx)
  
  X_train <- X_scaled[train_idx, selected_vars, drop = FALSE]
  y_train <- y[train_idx]
  X_test  <- X_scaled[test_idx, selected_vars, drop = FALSE]
  y_test  <- y[test_idx]
  
  mod <- glmnet(X_train, y_train, alpha = best_alpha, lambda = best_lambda)
  pred <- predict(mod, newx = X_test, s = best_lambda)
  
  mse_cv[i] <- mean((y_test - pred)^2)
}

mean_mse <- mean(mse_cv)
rmse_cv  <- sqrt(mean_mse)


cat("MSE CV sur le modèle final :", mean_mse, "\n")
cat("RMSE CV sur le modèle final :", rmse_cv, "\n")
```
```{r}
library(glmnet)
library(dplyr)

# set.seed(123) # seed initial

# Préparer les données
X <- reg_data %>% select(-y) %>% as.matrix()
y <- reg_data$y
X_scaled <- scale(X)

# Grille fine de lambda et alpha
lambda_grid <- 10^seq(-2, 2, length.out = 200)
alpha_grid  <- seq(0.8, 1, by = 0.02)

# Paramètres de repeated CV
n_repeats <- 20           # nombre de répétitions avec différentes seeds
seeds <- sample(1:10000, n_repeats) # seeds différentes pour chaque répétition

# Stocker les résultats
results <- list()

for(a in alpha_grid){
  mse_seeds <- numeric(n_repeats)
  
  for(i in seq_along(seeds)){
    set.seed(seeds[i])
    cv_mod <- cv.glmnet(X_scaled, y, alpha = a, nfolds = 10, lambda = lambda_grid)
    mse_seeds[i] <- min(cv_mod$cvm)
  }
  
  # Moyenne de la MSE sur toutes les seeds
  results[[as.character(a)]] <- mean(mse_seeds)
}

# Sélection du meilleur alpha
best_alpha <- as.numeric(names(results)[which.min(unlist(results))])
cat("Meilleur alpha moyen sur repeated CV :", best_alpha, "\n")
best_mse   <- results[[as.character(best_alpha)]]
cat("MSE CV moyen sur repeated CV :", best_mse, "\n")

# Fit final avec alpha optimal
final_cv <- cv.glmnet(X_scaled, y, alpha = best_alpha, nfolds = 10, lambda = lambda_grid)
best_lambda <- final_cv$lambda.min
cat("Lambda correspondant au meilleur alpha :", best_lambda, "\n")

# Variables sélectionnées
coef_selected <- coef(final_cv, s = "lambda.min")
selected_vars <- rownames(coef_selected)[coef_selected[,1] != 0]
selected_vars <- selected_vars[selected_vars != "(Intercept)"]
cat("Variables sélectionnées :", selected_vars, "\n\n")

# Refit final sur toutes les données
final_model <- glmnet(X_scaled, y, alpha = best_alpha, lambda = best_lambda)

# Validation croisée manuelle pour MSE réaliste
k <- 10
folds <- sample(rep(1:k, length.out = nrow(X_scaled)))
mse_cv <- numeric(k)

for(i in 1:k){
  test_idx <- which(folds == i)
  train_idx <- setdiff(1:nrow(X_scaled), test_idx)
  
  X_train <- X_scaled[train_idx, selected_vars, drop = FALSE]
  y_train <- y[train_idx]
  X_test  <- X_scaled[test_idx, selected_vars, drop = FALSE]
  y_test  <- y[test_idx]
  
  mod <- glmnet(X_train, y_train, alpha = best_alpha, lambda = best_lambda)
  pred <- predict(mod, newx = X_test, s = best_lambda)
  
  mse_cv[i] <- mean((y_test - pred)^2)
}

mean_mse <- mean(mse_cv)
rmse_cv  <- sqrt(mean_mse)

cat("MSE CV final :", mean_mse, "\n")
cat("RMSE CV final :", rmse_cv, "\n")
```


##### Test de PCR, PLS, Bayesian Ridge et NN
```{r}
library(dplyr)
library(pls)   # PCR et PLS
library(MASS)  # Ridge
library(nnet)  # Neural Network

set.seed(123)


# Préparation des données
X <- as.matrix(reg_data[, setdiff(names(reg_data), "y")])
y <- reg_data$y
X_scaled <- scale(X)
df <- data.frame(y = y, X_scaled)


k <- 10
folds <- sample(rep(1:k, length.out = nrow(df)))

mse_fold <- function(y_true, y_pred){
  mean((y_true - y_pred)^2)
}

results <- list()

# PCR
mse_pcr <- numeric(k)
for(i in 1:k){
  train_idx <- which(folds != i)
  test_idx  <- which(folds == i)
  
  train_df <- df[train_idx, ]
  test_df  <- df[test_idx, ]
  
  pcr_mod <- pcr(y ~ ., data = train_df, scale = TRUE, validation = "CV")
  # Nombre optimal de composantes pour PCR
  rmsep_vals <- RMSEP(pcr_mod)$val[1,,1]
  ncomp <- which.min(rmsep_vals)
  
  pred <- predict(pcr_mod, test_df, ncomp = ncomp)
  mse_pcr[i] <- mse_fold(test_df$y, pred)
}
results$PCR <- mean(mse_pcr)

# LASSO
mse_lasso <- numeric(k)
for(i in 1:k){
  train_idx <- which(folds != i)
  test_idx  <- which(folds == i)
  
  train_df <- df[train_idx, ]
  test_df  <- df[test_idx, ]
  ytrain <- train_df$y
  xtrain <- as.matrix(train_df[, setdiff(names(train_df), "y")])
  xtest  <- as.matrix(test_df[, setdiff(names(test_df), "y")])
  
  cv.out<-cv.glmnet(xtrain,ytrain,alpha=1)
  reg <- glmnet(x = xtrain, y = ytrain,lambda=cv.out$lambda.min,alpha=1)
  
  pred<-predict(reg,s=cv.out$lambda.min,newx=xtest)
  mse_lasso[i] <- mse_fold(test_df$y, pred)
}
results$LASSO <- mean(mse_lasso)

# PLS
mse_pls <- numeric(k)
for(i in 1:k){
  train_idx <- which(folds != i)
  test_idx  <- which(folds == i)
  
  train_df <- df[train_idx, ]
  test_df  <- df[test_idx, ]
  
  pls_mod <- plsr(y ~ ., data = train_df, scale = TRUE, validation = "CV")
  rmsep_vals <- RMSEP(pls_mod)$val[1,,1]
  ncomp <- which.min(rmsep_vals)
  
  pred <- predict(pls_mod, test_df, ncomp = ncomp)
  mse_pls[i] <- mse_fold(test_df$y, pred)
}
results$PLS <- mean(mse_pls)


# Bayesian Ridge 
lambda_grid <- seq(0, 100, length.out = 50)
mse_ridge <- numeric(k)
for(i in 1:k){
  train_idx <- which(folds != i)
  test_idx  <- which(folds == i)
  
  X_train <- X_scaled[train_idx, ]
  y_train <- y[train_idx]
  X_test  <- X_scaled[test_idx, ]
  y_test  <- y[test_idx]
  
  ridge_mod <- lm.ridge(y_train ~ X_train, lambda = lambda_grid)
  lambda_best <- ridge_mod$lambda[which.min(ridge_mod$GCV)]
  
  coef_ridge <- coef(lm.ridge(y_train ~ X_train, lambda = lambda_best))
  intercept <- coef_ridge[1]
  beta <- coef_ridge[-1]
  pred <- X_test %*% beta + intercept
  mse_ridge[i] <- mse_fold(y_test, pred)
}
results$BayesianRidge <- mean(mse_ridge)


# Neural Network simple
mse_nn <- numeric(k)
for(i in 1:k){
  train_idx <- which(folds != i)
  test_idx  <- which(folds == i)
  
  train_df <- df[train_idx, ]
  test_df  <- df[test_idx, ]
  
  nn_mod <- nnet(y ~ ., data = train_df, size = 5, linout = TRUE, trace = FALSE, maxit = 500)
  pred <- predict(nn_mod, test_df)
  mse_nn[i] <- mse_fold(test_df$y, pred)
}
results$NN <- mean(mse_nn)

# Résultats
res_df <- data.frame(
  Model = names(results),
  MSE_CV = unlist(results)
)
print(res_df)
```
